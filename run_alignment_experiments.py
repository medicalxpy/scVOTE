#!/usr/bin/env python3
"""
Run scFASTopic training + evaluation over a fixed grid of
datasets × topic numbers × alignment methods, and save all
evaluation metrics into a single CSV file.

Datasets:
  - PBMC4k
  - Spleen
  - kidney
  - lung

For each dataset, this script:
  1) Cleans up any previous results generated by older
     versions of this script for the same grid
     (topic/cell/gene/topic matrices and CSV).
  2) Ensures scVI embeddings exist (via get_cell_emb.py).
  3) Trains scFASTopic with n_topics in {10, 20, 50}
     under two alignment modes:
       - structure   (Laplacian + CKA only)
       - contrastive (GenePT contrastive only).
  4) Runs evaluation.evaluate to compute all metrics.
  5) Writes a CSV with one row per (dataset, n_topics, alignment)
     into results/alignment_experiments_metrics.csv
     (same path/format as before).
"""

from __future__ import annotations

import json
import subprocess
import sys
import time
from dataclasses import asdict
from pathlib import Path
from typing import Dict, List, Any, Tuple

import pandas as pd

from evaluation import EvalConfig, evaluate


ROOT_DIR = Path(__file__).resolve().parent
DATA_DIR = ROOT_DIR / "data"
RESULTS_DIR = ROOT_DIR / "results"
EMB_DIR = RESULTS_DIR / "cell_embedding"


DATASETS: Dict[str, Path] = {
    "PBMC4k": DATA_DIR / "PBMC4k.h5ad",
    "Spleen": DATA_DIR / "Spleen.h5ad",
    "kidney": DATA_DIR / "kidney.h5ad",
    "lung": DATA_DIR / "lung.h5ad",
}

TOPIC_COUNTS: List[int] = [10, 20, 50]
ALIGN_METHODS: List[str] = ["structure", "contrastive"]

# Training hyperparameters (mirroring train.sh defaults where possible)
EPOCHS: int = 1000
LR: float = 0.01
DT_ALPHA: float = 1.0
TW_ALPHA: float = 8.0
THETA_TEMP: float = 5.0
N_TOP_GENES_TRAIN: int = 0
SEED: int = 42

# Alignment hyperparameters
ALIGN_ALPHA: float = 1e-3
ALIGN_BETA: float = 1e-3
ALIGN_K: int = 512
CKA_SAMPLE_N: int = 1024

# GenePT contrastive loss default weight (used when contrastive is enabled)
GENEPT_LOSS_WEIGHT: float = 1e-3


def _combo_run_dataset(dataset: str, alignment: str) -> str:
    """Return the dataset label used for training outputs for a combo."""
    return f"{dataset}_scVI_{alignment}"


def _cleanup_single_combo(run_dataset: str, n_topics: int) -> None:
    """
    Delete old FASTopic result files for a single (run_dataset, n_topics) combo.

    This removes the matrices produced by train_fastopic.py for the given
    combo, without touching embeddings or other experiments.
    """
    # Core matrix subdirs and filename templates (must match train_fastopic.py)
    cell_topic = (
        RESULTS_DIR
        / "cell_topic"
        / f"{run_dataset}_cell_topic_matrix_{n_topics}.pkl"
    )
    topic_gene = (
        RESULTS_DIR
        / "topic_gene"
        / f"{run_dataset}_topic_gene_matrix_{n_topics}.pkl"
    )
    gene_emb = (
        RESULTS_DIR
        / "gene_embedding"
        / f"{run_dataset}_gene_embeddings_{n_topics}.pkl"
    )
    gene_names = (
        RESULTS_DIR
        / "gene_embedding"
        / f"{run_dataset}_gene_names_{n_topics}.pkl"
    )
    topic_emb = (
        RESULTS_DIR
        / "topic_embedding"
        / f"{run_dataset}_topic_embeddings_{n_topics}.pkl"
    )
    gpu_stats = (
        RESULTS_DIR
        / "gpu_stats"
        / f"{run_dataset}_gpu_stats_{n_topics}.json"
    )

    for p in [cell_topic, topic_gene, gene_emb, gene_names, topic_emb, gpu_stats]:
        try:
            p.unlink(missing_ok=True)
            if p.exists():
                # Rare race: if still exists after unlink attempt, just skip.
                continue
            print(f"[run_alignment_experiments] Removed old file: {p}")
        except Exception as exc:  # noqa: BLE001
            print(
                f"[run_alignment_experiments] Warning: failed to remove {p}: {exc}"
            )


def cleanup_previous_results() -> None:
    """
    Remove results that were produced by earlier runs of this script
    for the same (dataset, n_topics, alignment) grid.

    This includes:
      - The aggregated CSV: results/alignment_experiments_metrics.csv
      - All topic/cell/gene/topic matrices for those combos.
    """
    # Remove per-combo matrices
    for dataset in DATASETS.keys():
        for n_topics in TOPIC_COUNTS:
            for alignment in ALIGN_METHODS:
                run_dataset = _combo_run_dataset(dataset, alignment)
                _cleanup_single_combo(run_dataset, n_topics)

    # Remove previous aggregated CSV
    csv_path = RESULTS_DIR / "alignment_experiments_metrics.csv"
    try:
        csv_path.unlink(missing_ok=True)
        if not csv_path.exists():
            print(
                "[run_alignment_experiments] Removed old CSV: "
                f"{csv_path}"
            )
    except Exception as exc:  # noqa: BLE001
        print(
            f"[run_alignment_experiments] Warning: failed to remove CSV "
            f"{csv_path}: {exc}"
        )


def _run(cmd: List[str]) -> None:
    """Run a subprocess, raising on failure."""
    print(f"[run_alignment_experiments] Running: {' '.join(cmd)}")
    subprocess.run(cmd, check=True)


def _run_timed(cmd: List[str]) -> float:
    """Run a subprocess and return elapsed time in seconds."""
    print(f"[run_alignment_experiments] Running (timed): {' '.join(cmd)}")
    start = time.perf_counter()
    subprocess.run(cmd, check=True)
    end = time.perf_counter()
    return float(end - start)


def ensure_embedding(dataset: str, adata_path: Path) -> Path:
    """Ensure scVI embedding exists for the dataset, return its path."""
    EMB_DIR.mkdir(parents=True, exist_ok=True)
    emb_path = EMB_DIR / f"{dataset}_scvi.pkl"
    if emb_path.exists():
        print(f"[run_alignment_experiments] Found existing embedding: {emb_path}")
        return emb_path

    cmd = [
        sys.executable,
        str(ROOT_DIR / "get_cell_emb.py"),
        "--input_data",
        str(adata_path),
        "--dataset_name",
        dataset,
        "--output_dir",
        str(EMB_DIR),
        "--n_latent",
        "128",
        "--n_top_genes",
        "0",
        "--early_stopping",
    ]
    _run(cmd)
    return emb_path


def _load_gpu_stats(run_dataset: str, n_topics: int) -> Dict[str, Any]:
    """
    Load GPU memory statistics for a given (run_dataset, n_topics) combo,
    if available. Returns a dict that can be merged into the CSV row.
    """
    stats_path = (
        RESULTS_DIR
        / "gpu_stats"
        / f"{run_dataset}_gpu_stats_{n_topics}.json"
    )
    if not stats_path.exists():
        return {}
    try:
        with open(stats_path, "r", encoding="utf-8") as f:
            data = json.load(f)
    except Exception as exc:  # noqa: BLE001
        print(
            f"[run_alignment_experiments] Warning: failed to load GPU stats "
            f"from {stats_path}: {exc}"
        )
        return {}

    gpu_stats: Dict[str, Any] = {}
    for key in ("gpu_max_mem_allocated_mb", "gpu_max_mem_reserved_mb"):
        if key in data:
            gpu_stats[key] = data[key]
    return gpu_stats


def train_single(
    dataset: str,
    adata_path: Path,
    emb_path: Path,
    n_topics: int,
    alignment: str,
) -> Tuple[str, float, Dict[str, Any]]:
    """
    Train scFASTopic for a single (dataset, n_topics, alignment) combo.

    Returns the dataset label used for saving results (and for evaluation).
    """
    if alignment not in ALIGN_METHODS:
        raise ValueError(f"Unknown alignment method: {alignment}")

    # Use distinct dataset labels so results don't collide on disk
    run_dataset = _combo_run_dataset(dataset, alignment)

    base_cmd: List[str] = [
        sys.executable,
        str(ROOT_DIR / "train_fastopic.py"),
        "--embedding_file",
        str(emb_path),
        "--adata_path",
        str(adata_path),
        "--dataset",
        run_dataset,
        "--n_topics",
        str(n_topics),
        "--epochs",
        str(EPOCHS),
        "--lr",
        str(LR),
        "--DT_alpha",
        str(DT_ALPHA),
        "--TW_alpha",
        str(TW_ALPHA),
        "--theta_temp",
        str(THETA_TEMP),
        "--n_top_genes",
        str(N_TOP_GENES_TRAIN),
        "--align_alpha",
        str(ALIGN_ALPHA),
        "--align_beta",
        str(ALIGN_BETA),
        "--align_knn_k",
        str(ALIGN_K),
        "--align_cka_sample_n",
        str(CKA_SAMPLE_N),
        "--seed",
        str(SEED),
        "--output_dir",
        str(RESULTS_DIR),
    ]

    # Alignment-specific flags:
    # - structure: structural alignment only (no GenePT contrastive)
    # - contrastive: GenePT contrastive only (no structural alignment)
    if alignment == "structure":
        base_cmd.extend(
            [
                "--structure",
                "--genept_loss_weight",
                "0",
            ]
        )
    elif alignment == "contrastive":
        base_cmd.extend(
            [
                "--no_align",
                "--contrastive",
                "--genept_loss_weight",
                str(GENEPT_LOSS_WEIGHT),
            ]
        )

    elapsed = _run_timed(base_cmd)
    gpu_stats = _load_gpu_stats(run_dataset, n_topics)
    return run_dataset, elapsed, gpu_stats


def evaluate_single(
    dataset: str,
    adata_path: Path,
    run_dataset: str,
    n_topics: int,
    alignment: str,
    train_time_sec: float,
    gpu_stats: Dict[str, Any],
) -> Dict[str, Any]:
    """Run evaluation.evaluate and return a flat metrics dict for CSV."""
    cfg = EvalConfig(
        adata_path=str(adata_path),
        results_dir=str(RESULTS_DIR),
        dataset=run_dataset,
        n_topics=n_topics,
        cell_topic_file=None,
        label_key=None,
        tag=alignment,
        res_min=0.0,
        res_max=2.0,
        res_step=0.1,
        out_dir=None,
        seed=SEED,
    )

    try:
        metrics = evaluate(cfg)
    except Exception as exc:  # noqa: BLE001
        print(
            f"[run_alignment_experiments] Evaluation failed for "
            f"{dataset}, n_topics={n_topics}, alignment={alignment}: {exc}"
        )
        metrics = {}

    row: Dict[str, Any] = {
        "base_dataset": dataset,
        "run_dataset": run_dataset,
        "alignment": alignment,
        "n_topics": n_topics,
        "train_time_sec": train_time_sec,
        "train_time_min": train_time_sec / 60.0 if train_time_sec is not None else None,
    }

    # Attach GPU metrics (if available for this combo)
    if gpu_stats:
        row.update(gpu_stats)

    # Flatten EvalConfig (for reproducibility) and metrics into the row
    row.update({f"cfg_{k}": v for k, v in asdict(cfg).items()})
    for k, v in metrics.items():
        row[f"metric_{k}"] = v
    return row


def main() -> int:
    RESULTS_DIR.mkdir(parents=True, exist_ok=True)

    # Step 0: clean up any previous results produced by this script
    print("[run_alignment_experiments] Cleaning up previous grid results...")
    cleanup_previous_results()

    all_rows: List[Dict[str, Any]] = []

    for dataset, adata_path in DATASETS.items():
        if not adata_path.exists():
            print(f"[run_alignment_experiments] Skipping {dataset}: {adata_path} not found")
            continue

        print(f"\n=== Dataset: {dataset} ({adata_path}) ===")
        try:
            emb_path = ensure_embedding(dataset, adata_path)
        except Exception as exc:  # noqa: BLE001
            print(
                f"[run_alignment_experiments] Embedding extraction failed for "
                f"{dataset}: {exc}. Skipping this dataset."
            )
            continue

        for n_topics in TOPIC_COUNTS:
            for alignment in ALIGN_METHODS:
                print(
                    f"\n>>> Training/evaluating: dataset={dataset}, "
                    f"n_topics={n_topics}, alignment={alignment}"
                )
                try:
                    run_dataset, train_time_sec, gpu_stats = train_single(
                        dataset=dataset,
                        adata_path=adata_path,
                        emb_path=emb_path,
                        n_topics=n_topics,
                        alignment=alignment,
                    )
                except Exception as exc:  # noqa: BLE001
                    print(
                        f"[run_alignment_experiments] Training failed for "
                        f"{dataset}, n_topics={n_topics}, alignment={alignment}: {exc}. "
                        f"Skipping this combo."
                    )
                    continue
                row = evaluate_single(
                    dataset=dataset,
                    adata_path=adata_path,
                    run_dataset=run_dataset,
                    n_topics=n_topics,
                    alignment=alignment,
                    train_time_sec=train_time_sec,
                    gpu_stats=gpu_stats,
                )
                all_rows.append(row)

    if not all_rows:
        print("[run_alignment_experiments] No runs completed; CSV will not be written.")
        return 1

    df = pd.DataFrame(all_rows)
    out_csv = RESULTS_DIR / "alignment_experiments_metrics.csv"
    df.to_csv(out_csv, index=False)
    print(f"\n[run_alignment_experiments] Saved aggregated metrics to: {out_csv}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
